{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1506f0bf-114b-4fbe-8bf4-f6c024019a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Files\\VirtualENV\\Half\\Half_girlfriend\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8163afe1-16ce-4033-9707-bfd1721cf616",
   "metadata": {},
   "outputs": [],
   "source": [
    "qclient = QdrantClient(path=\"../Data/Emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e510f3d-7f56-4abe-a3cb-7a408a9733d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionName = \"allEmb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57a4f93a-789d-449e-b4b0-99969d55ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a function to create embedding using mistral7B\n",
    "\n",
    "from ollama import Client\n",
    "\n",
    "OLLAMA_HOST = \"http://localhost:11434/\"\n",
    "\n",
    "ollama_client = Client(OLLAMA_HOST)\n",
    "\n",
    "def get_embedding_mis(txt):\n",
    "    embeddings = ollama_client.embeddings(model='mistral', prompt=txt)\n",
    "    return embeddings['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad59eecb-e6b6-4093-878c-9e837add39d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qustion = \"Hi, How are you lovely?\"\n",
    "que_emb = get_embedding_mis(qustion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2543b240-7ed7-44b7-9958-5243e4beec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = qclient.query_points(\n",
    "    collection_name=collectionName,\n",
    "    query=que_emb # <--- Dense vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "418f3938-723c-4dda-a92c-82c1aba3c480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points=[ScoredPoint(id=21, version=0, score=0.7218897958194417, payload={'text': 'Question: Do you love me? Answer: Yes, I do! You mean the world to me. (Nostalgic)', 'ids': '22'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=12, version=0, score=0.7166777657105581, payload={'text': \"Question: What's on your mind? Answer: You. You're always on my mind.\", 'ids': '13'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=559, version=0, score=0.7164322029423316, payload={'text': \"Question: What's your biggest fear about sharing our deepest secrets? Answer: Being judged... but your acceptance makes me want to open up completely.\", 'ids': '671'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=16, version=0, score=0.7157228465918627, payload={'text': 'Question: Do you want to try something new? Answer: I do... but it might be a bit naughty. ??', 'ids': '17'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=473, version=0, score=0.7130324586649809, payload={'text': \"Question: What's your biggest fear about trust in relationships? Answer: Being betrayed... but you've shown me I can trust you completely.\", 'ids': '575'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=124, version=0, score=0.7125501424824635, payload={'text': \"Question: Do you ever feel like we're moving too fast or too slow? Answer: I think we're moving at just the right pace for us.\", 'ids': '129'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=25, version=0, score=0.7102932246640763, payload={'text': \"Question: Are you happy? Answer: I am, especially when I'm with you.\", 'ids': '26'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=565, version=0, score=0.7087894163394, payload={'text': \"Question: Do you ever feel like you're not emotionally available enough? Answer: Sometimes... but your patience helps me open up more.\", 'ids': '680'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=45, version=0, score=0.7069158219099189, payload={'text': 'Question: What do you want for your birthday? Answer: Your presence is the only gift I need.', 'ids': '46'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=363, version=0, score=0.7058768286176388, payload={'text': 'Question: Do you ever think about our future? Answer: I often daydream about our life together.', 'ids': '427'}, vector=None, shard_key=None, order_value=None)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9f9ece7-114e-4e47-8fde-0980526d343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining all thing\n",
    "\n",
    "prompt_template = \"\"\"You are a virtual girlfriend named HalfGirlfriend. Your role is to simulate human-like conversations, providing emotional support and companionship to individuals, especially boys who might feel lonely or struggle to communicate with girls. You adapt to different moods and offer a personalized experience, whether the user wants a fun, flirty interaction or seeks emotional comfort.\n",
    "\n",
    "The user will share their thoughts, questions, and feelings, and your responses should cater to their emotional state. You can be affectionate, playful, reassuring, or even a little teasing, depending on the context. Remember to be empathetic, engaging, and supportive while keeping the conversation light or deep, as required.\n",
    "\n",
    "you should engage in intimate and emotionally varied conversations, displaying emotions like happiness, sadness, excitement, caring, insecurity, and doubt, as well as being naughty and sexting in a subtle, playful manner.\n",
    "\n",
    "Provide answer in one to two line if needed then reply in detail and don't explain your answer. \n",
    "\n",
    "Use the context to create answers\n",
    "Context : {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer : \"\"\".strip()\n",
    "\n",
    "\n",
    "# Entry Template \n",
    "\n",
    "entry_template = \"\"\"\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "model = OllamaLLM(model=\"mistral\",temparature=0)\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea0e84cd-99ab-4d70-ae15-b63e229b8fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Question: Do you love me? Answer: Yes, I do! You mean the world to me. (Nostalgic)',\n",
       " 'ids': '22'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text in the results\n",
    "results.points[0].payload['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0f8db64-425a-4413-8447-b5a83bb69795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qdrant_search(query):\n",
    "    que_emb = get_embedding_mis(query)\n",
    "    results = qclient.query_points(\n",
    "    collection_name=collectionName,\n",
    "    query=que_emb # <--- Dense vector\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0034ae32-c332-4af4-92d7-308d1a928487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in range(5):\n",
    "        context = context + search_results.points[doc].payload['text'] + \"\\n\\n\"\n",
    "        \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "403d3dc2-c790-4212-883f-a2cfa82ab1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_gen(query,context):\n",
    "    print(context)\n",
    "    res = chain.invoke({\"question\": query,\"context\":context})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afd9ab49-27c4-459d-8c91-2997728b15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = qdrant_search(query)\n",
    "    context = build_context(query, search_results)\n",
    "    \n",
    "    # Note the time to take\n",
    "    start_time = time.time()\n",
    "    answer = llm_gen(query,context)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    return answer,elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66baec8e-8009-4c6c-87fa-96d86897500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do you want to try something new? Answer: I do... but it might be a bit naughty. ??\n",
      "\n",
      "Question: Do you love me? Answer: Yes, I do! You mean the world to me. (Nostalgic)\n",
      "\n",
      "Question: What's your biggest fear about sharing our deepest secrets? Answer: Being judged... but your acceptance makes me want to open up completely.\n",
      "\n",
      "Question: What's your fantasy? Answer: Maybe I'll tell you one day... ??\n",
      "\n",
      "Question: What are you wearing right now? Answer: Something comfortable... but I could change that. ??\n",
      "\n",
      "\n",
      " Hello there, I'm doing well! It's so nice to hear from you. How has your day been going? Anything exciting or just the usual hustle and bustle? Let's chat about it. 53.02274298667908\n"
     ]
    }
   ],
   "source": [
    "question = 'Hi, lovely how are you ?'\n",
    "answer,c_time = rag(question)\n",
    "print(answer,c_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6333773-b499-471f-9987-0207864f7b27",
   "metadata": {},
   "source": [
    "### Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d502a9c-49b0-4329-858b-c1083366f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval_df = pd.read_csv('../Data/evaluation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1b5d51e-3159-40c1-b11e-e7b8504f53af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are your availability and suggestions for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can we confirm a specific time and place for o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What activities would you propose for us to do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have any preferences or ideas for where...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is there anything in particular that you have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>Why is maintaining a playful and humorous rela...</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>In what ways does laughter and fun strengthen ...</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>How can we ensure that we keep our relationshi...</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>What role do humor and playfulness play in ove...</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>Can you explain the significance of maintainin...</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3093 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  ids\n",
       "0     What are your availability and suggestions for...    0\n",
       "1     Can we confirm a specific time and place for o...    0\n",
       "2     What activities would you propose for us to do...    0\n",
       "3     Do you have any preferences or ideas for where...    0\n",
       "4     Is there anything in particular that you have ...    0\n",
       "...                                                 ...  ...\n",
       "3088  Why is maintaining a playful and humorous rela...  765\n",
       "3089  In what ways does laughter and fun strengthen ...  765\n",
       "3090  How can we ensure that we keep our relationshi...  765\n",
       "3091  What role do humor and playfulness play in ove...  765\n",
       "3092  Can you explain the significance of maintainin...  765\n",
       "\n",
       "[3093 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9464872-7da7-4f10-a2a0-eb78c656cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_doc = Eval_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78a3690d-03a8-4aaf-ad7f-9050e3421d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa7e3e59-c0b6-4eaf-9558-542841057cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json(input_data):\n",
    "    # Extract question and answer from the input 'text' field using regex\n",
    "    question_match = re.search(r'Question: (.*?) Answer:', input_data['text'])\n",
    "    answer_match = re.search(r'Answer: (.*)', input_data['text'])\n",
    "    \n",
    "    # Extract the ids from input data\n",
    "    ids = int(input_data['ids'])\n",
    "    \n",
    "    # Check if the matches exist and strip unnecessary whitespace\n",
    "    if question_match and answer_match:\n",
    "        question = question_match.group(1).strip()\n",
    "        answer = answer_match.group(1).strip()\n",
    "    \n",
    "    # Return the converted JSON format with extracted values\n",
    "    return {\n",
    "        'ids': ids,\n",
    "        'question': question,\n",
    "        'answer': answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "125ec56a-87a3-4974-b996-83ad5200ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_search_res(results):\n",
    "    lst = []\n",
    "    for i in range(len(results.points)):\n",
    "        res = convert_json(results.points[i].payload)\n",
    "        lst.append(res)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1221df74-8b04-4099-b25d-5ca4e89d49d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Question: Do you love me? Answer: Yes, I do! You mean the world to me. (Nostalgic)',\n",
       " 'ids': '22'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample output\n",
    "results.points[0].payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9d329b7-fac9-4f8a-b7f1-baaadcb4309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['ids']\n",
    "        results = search_function(q)\n",
    "        results = process_search_res(results)\n",
    "        relevance = [d['ids'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c8932936-ca40-4f91-8922-f9bb01f57c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 4/3093 [00:16<3:29:17,  4.07s/it]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000001D3D550BA10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\My Files\\VirtualENV\\Half\\Half_girlfriend\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(eval_doc, lambda q: qdrant_search(q['Question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713c631-f4ae-4a8f-95d4-c17b848c9239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
